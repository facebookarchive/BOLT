//===--- Passes/MCF.cpp ---------------------------------------------------===//
//
//                     The LLVM Compiler Infrastructure
//
// This file is distributed under the University of Illinois Open Source
// License. See LICENSE.TXT for details.
//
//===----------------------------------------------------------------------===//
//
//===----------------------------------------------------------------------===//

#include "MCF.h"
#include "BinaryFunction.h"
#include "BinaryPassManager.h"
#include "Passes/DataflowInfoManager.h"
#include "llvm/ADT/DenseMap.h"
#include "llvm/Support/CommandLine.h"
#include "llvm/Support/Timer.h"
#include <vector>
#include <limits>
#include <algorithm>
#include <cmath>

#undef  DEBUG_TYPE
#define DEBUG_TYPE "mcf"

using namespace llvm;
using namespace bolt;

namespace opts {

extern cl::OptionCategory BoltOptCategory;

extern cl::opt<bool> TimeOpts;

static cl::opt<bool>
IterativeGuess("iterative-guess",
  cl::desc("in non-LBR mode, guess edge counts using iterative technique"),
  cl::ZeroOrMore,
  cl::init(false),
  cl::Hidden,
  cl::cat(BoltOptCategory));

static cl::opt<bool>
EqualizeBBCounts("equalize-bb-counts",
  cl::desc("in non-LBR mode, use same count for BBs "
           "that should have equivalent count"),
  cl::ZeroOrMore,
  cl::init(false),
  cl::Hidden,
  cl::cat(BoltOptCategory));

static cl::opt<bool>
UseRArcs("mcf-use-rarcs",
  cl::desc("in MCF, consider the possibility of cancelling flow to balance "
           "edges"),
  cl::ZeroOrMore,
  cl::init(false),
  cl::Hidden,
  cl::cat(BoltOptCategory));

} // namespace opts

/// This is the network simplex algorihtm of the LEMON library adapted to run
/// with BOLT data structures. Copyright of this code is stated below.

// Copyright (C) 2003-2012 Egervary Jeno Kombinatorikus Optimalizalasi
// Kutatocsoport (Egervary Research Group on Combinatorial Optimization,
//                EGRES).
//
//===========================================================================
//  Boost Software License, Version 1.0
//  ===========================================================================
//
//  Permission is hereby granted, free of charge, to any person or organization
//  obtaining a copy of the software and accompanying documentation covered by
//  this license (the "Software") to use, reproduce, display, distribute,
//  execute, and transmit the Software, and to prepare derivative works of the
//  Software, and to permit third-parties to whom the Software is furnished to
//  do so, all subject to the following:
//
//   The copyright notices in the Software and this entire statement, including
//   the above license grant, this restriction and the following disclaimer,
//   must be included in all copies of the Software, in whole or in part, and
//   all derivative works of the Software, unless such copies or derivative
//   works are solely in the form of machine-executable object code generated by
//   a source language processor.
//
//   THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
//   IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
//   FITNESS FOR A PARTICULAR PURPOSE, TITLE AND NON-INFRINGEMENT. IN NO EVENT
//   SHALL THE COPYRIGHT HOLDERS OR ANYONE DISTRIBUTING THE SOFTWARE BE LIABLE
//   FOR ANY DAMAGES OR OTHER LIABILITY, WHETHER IN CONTRACT, TORT OR OTHERWISE,
//   ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
//   DEALINGS IN THE SOFTWARE.
// End license
namespace lemon {

/// \brief Dummy type to make it easier to create invalid iterators.
struct Invalid {
 public:
  bool operator==(Invalid) { return true;  }
  bool operator!=(Invalid) { return false; }
  bool operator< (Invalid) { return false; }
};

const Invalid INVALID = Invalid();

#define LEMON_ASSERT(x, t) assert(x && t)
#define LEMON_DEBUG(x, t) DEBUG(assert(x && t))

/// \tparam GR The digraph type the algorithm runs on.
/// \tparam V The number type used for flow amounts, capacity bounds
/// and supply values in the algorithm. By default, it is \c int.
/// \tparam C The number type used for costs and potentials in the
/// algorithm. By default, it is the same as \c V.
///
/// \warning Both \c V and \c C must be signed number types.
/// \warning All input data (capacities, supply values, and costs) must
/// be integer.
///
/// \note %NetworkSimplex provides five different pivot rule
/// implementations, from which the most efficient one is used
/// by default. For more information, see \ref PivotRule.
template <typename GR, typename V = int, typename C = V>
class NetworkSimplex
{
public:

  /// The type of the flow amounts, capacity bounds and supply values
  typedef V Value;
  /// The type of the arc costs
  typedef C Cost;

public:

  /// \brief Problem type constants for the \c run() function.
  ///
  /// Enum type containing the problem type constants that can be
  /// returned by the \ref run() function of the algorithm.
  enum ProblemType {
    /// The problem has no feasible solution (flow).
    INFEASIBLE,
    /// The problem has optimal solution (i.e. it is feasible and
    /// bounded), and the algorithm has found optimal flow and node
    /// potentials (primal and dual solutions).
    OPTIMAL,
    /// The objective function of the problem is unbounded, i.e.
    /// there is a directed cycle having negative total cost and
    /// infinite upper bound.
    UNBOUNDED
  };

  /// \brief Constants for selecting the type of the supply constraints.
  ///
  /// Enum type containing constants for selecting the supply type,
  /// i.e. the direction of the inequalities in the supply/demand
  /// constraints of the \ref min_cost_flow "minimum cost flow problem".
  ///
  /// The default supply type is \c GEQ, the \c LEQ type can be
  /// selected using \ref supplyType().
  /// The equality form is a special case of both supply types.
  enum SupplyType {
    /// This option means that there are <em>"greater or equal"</em>
    /// supply/demand constraints in the definition of the problem.
    GEQ,
    /// This option means that there are <em>"less or equal"</em>
    /// supply/demand constraints in the definition of the problem.
    LEQ
  };

  /// \brief Constants for selecting the pivot rule.
  ///
  /// Enum type containing constants for selecting the pivot rule for
  /// the \ref run() function.
  ///
  /// \ref NetworkSimplex provides five different implementations for
  /// the pivot strategy that significantly affects the running time
  /// of the algorithm.
  /// According to experimental tests conducted on various problem
  /// instances, \ref BLOCK_SEARCH "Block Search" and
  /// \ref ALTERING_LIST "Altering Candidate List" rules turned out
  /// to be the most efficient.
  /// Since \ref BLOCK_SEARCH "Block Search" is a simpler strategy that
  /// seemed to be slightly more robust, it is used by default.
  /// However, another pivot rule can easily be selected using the
  /// \ref run() function with the proper parameter.
  enum PivotRule {

    /// The \e First \e Eligible pivot rule.
    /// The next eligible arc is selected in a wraparound fashion
    /// in every iteration.
    FIRST_ELIGIBLE,

    /// The \e Best \e Eligible pivot rule.
    /// The best eligible arc is selected in every iteration.
    BEST_ELIGIBLE,

    /// The \e Block \e Search pivot rule.
    /// A specified number of arcs are examined in every iteration
    /// in a wraparound fashion and the best eligible arc is selected
    /// from this block.
    BLOCK_SEARCH,

    /// The \e Candidate \e List pivot rule.
    /// In a major iteration a candidate list is built from eligible arcs
    /// in a wraparound fashion and in the following minor iterations
    /// the best eligible arc is selected from this list.
    CANDIDATE_LIST,

    /// The \e Altering \e Candidate \e List pivot rule.
    /// It is a modified version of the Candidate List method.
    /// It keeps only a few of the best eligible arcs from the former
    /// candidate list and extends this list in every iteration.
    ALTERING_LIST
  };

private:

#define TEMPLATE_DIGRAPH_TYPEDEFS(Digraph)                              \
  typedef typename Digraph::Node Node;                                  \
  typedef typename Digraph::NodeIt NodeIt;                              \
  typedef typename Digraph::Arc Arc;                                    \
  typedef typename Digraph::ArcIt ArcIt;                                \
  typedef typename Digraph::InArcIt InArcIt;                            \
  typedef typename Digraph::OutArcIt OutArcIt

  TEMPLATE_DIGRAPH_TYPEDEFS(GR);

  typedef std::vector<int> IntVector;
  typedef std::vector<Value> ValueVector;
  typedef std::vector<Cost> CostVector;
  typedef std::vector<signed char> CharVector;
  // Note: vector<signed char> is used instead of vector<ArcState> and
  // vector<ArcDirection> for efficiency reasons

  // State constants for arcs
  enum ArcState {
    STATE_UPPER = -1,
    STATE_TREE  =  0,
    STATE_LOWER =  1
  };

  // Direction constants for tree arcs
  enum ArcDirection {
    DIR_DOWN = -1,
    DIR_UP   =  1
  };

private:

  // Data related to the underlying digraph
  const GR &_graph;
  int _node_num;
  int _arc_num;
  int _all_arc_num;
  int _search_arc_num;

  // Parameters of the problem
  bool _has_lower;
  SupplyType _stype;
  Value _sum_supply;

  // Data structures for storing the digraph
  std::map<Node, int> _node_id;
  std::map<Arc, int> _arc_id;
  IntVector _source;
  IntVector _target;
  bool _arc_mixing;

  // Node and arc data
  ValueVector _lower;
  ValueVector _upper;
  ValueVector _cap;
  CostVector _cost;
  ValueVector _supply;
  ValueVector _flow;
  CostVector _pi;

  // Data for storing the spanning tree structure
  IntVector _parent;
  IntVector _pred;
  IntVector _thread;
  IntVector _rev_thread;
  IntVector _succ_num;
  IntVector _last_succ;
  CharVector _pred_dir;
  CharVector _state;
  IntVector _dirty_revs;
  int _root;

  // Temporary data used in the current pivot iteration
  int in_arc, join, u_in, v_in, u_out, v_out;
  Value delta;

  const Value MAX;

public:

  /// \brief Constant for infinite upper bounds (capacities).
  ///
  /// Constant for infinite upper bounds (capacities).
  /// It is \c std::numeric_limits<Value>::infinity() if available,
  /// \c std::numeric_limits<Value>::max() otherwise.
  const Value INF;

private:

  // Implementation of the First Eligible pivot rule
  class FirstEligiblePivotRule
  {
  private:

    // References to the NetworkSimplex class
    const IntVector  &_source;
    const IntVector  &_target;
    const CostVector &_cost;
    const CharVector &_state;
    const CostVector &_pi;
    int &_in_arc;
    int _search_arc_num;

    // Pivot rule data
    int _next_arc;

  public:

    // Constructor
    FirstEligiblePivotRule(NetworkSimplex &ns) :
      _source(ns._source), _target(ns._target),
      _cost(ns._cost), _state(ns._state), _pi(ns._pi),
      _in_arc(ns.in_arc), _search_arc_num(ns._search_arc_num),
      _next_arc(0)
    {}

    // Find next entering arc
    bool findEnteringArc() {
      Cost c;
      for (int e = _next_arc; e != _search_arc_num; ++e) {
        c = _state[e] * (_cost[e] + _pi[_source[e]] - _pi[_target[e]]);
        if (c < 0) {
          _in_arc = e;
          _next_arc = e + 1;
          return true;
        }
      }
      for (int e = 0; e != _next_arc; ++e) {
        c = _state[e] * (_cost[e] + _pi[_source[e]] - _pi[_target[e]]);
        if (c < 0) {
          _in_arc = e;
          _next_arc = e + 1;
          return true;
        }
      }
      return false;
    }

  }; //class FirstEligiblePivotRule


  // Implementation of the Best Eligible pivot rule
  class BestEligiblePivotRule
  {
  private:

    // References to the NetworkSimplex class
    const IntVector  &_source;
    const IntVector  &_target;
    const CostVector &_cost;
    const CharVector &_state;
    const CostVector &_pi;
    int &_in_arc;
    int _search_arc_num;

  public:

    // Constructor
    BestEligiblePivotRule(NetworkSimplex &ns) :
      _source(ns._source), _target(ns._target),
      _cost(ns._cost), _state(ns._state), _pi(ns._pi),
      _in_arc(ns.in_arc), _search_arc_num(ns._search_arc_num)
    {}

    // Find next entering arc
    bool findEnteringArc() {
      Cost c, min = 0;
      for (int e = 0; e != _search_arc_num; ++e) {
        c = _state[e] * (_cost[e] + _pi[_source[e]] - _pi[_target[e]]);
        if (c < min) {
          min = c;
          _in_arc = e;
        }
      }
      return min < 0;
    }

  }; //class BestEligiblePivotRule


  // Implementation of the Block Search pivot rule
  class BlockSearchPivotRule
  {
  private:

    // References to the NetworkSimplex class
    const IntVector  &_source;
    const IntVector  &_target;
    const CostVector &_cost;
    const CharVector &_state;
    const CostVector &_pi;
    int &_in_arc;
    int _search_arc_num;

    // Pivot rule data
    int _block_size;
    int _next_arc;

  public:

    // Constructor
    BlockSearchPivotRule(NetworkSimplex &ns) :
      _source(ns._source), _target(ns._target),
      _cost(ns._cost), _state(ns._state), _pi(ns._pi),
      _in_arc(ns.in_arc), _search_arc_num(ns._search_arc_num),
      _next_arc(0)
    {
      // The main parameters of the pivot rule
      const double BLOCK_SIZE_FACTOR = 1.0;
      const int MIN_BLOCK_SIZE = 10;

      _block_size = std::max( int(BLOCK_SIZE_FACTOR *
                                  std::sqrt(double(_search_arc_num))),
                              MIN_BLOCK_SIZE );
    }

    // Find next entering arc
    bool findEnteringArc() {
      Cost c, min = 0;
      int cnt = _block_size;
      int e;
      for (e = _next_arc; e != _search_arc_num; ++e) {
        c = _state[e] * (_cost[e] + _pi[_source[e]] - _pi[_target[e]]);
        if (c < min) {
          min = c;
          _in_arc = e;
        }
        if (--cnt == 0) {
          if (min < 0) goto search_end;
          cnt = _block_size;
        }
      }
      for (e = 0; e != _next_arc; ++e) {
        c = _state[e] * (_cost[e] + _pi[_source[e]] - _pi[_target[e]]);
        if (c < min) {
          min = c;
          _in_arc = e;
        }
        if (--cnt == 0) {
          if (min < 0) goto search_end;
          cnt = _block_size;
        }
      }
      if (min >= 0) return false;

    search_end:
      _next_arc = e;
      return true;
    }

  }; //class BlockSearchPivotRule


  // Implementation of the Candidate List pivot rule
  class CandidateListPivotRule
  {
  private:

    // References to the NetworkSimplex class
    const IntVector  &_source;
    const IntVector  &_target;
    const CostVector &_cost;
    const CharVector &_state;
    const CostVector &_pi;
    int &_in_arc;
    int _search_arc_num;

    // Pivot rule data
    IntVector _candidates;
    int _list_length, _minor_limit;
    int _curr_length, _minor_count;
    int _next_arc;

  public:

    /// Constructor
    CandidateListPivotRule(NetworkSimplex &ns) :
      _source(ns._source), _target(ns._target),
      _cost(ns._cost), _state(ns._state), _pi(ns._pi),
      _in_arc(ns.in_arc), _search_arc_num(ns._search_arc_num),
      _next_arc(0)
    {
      // The main parameters of the pivot rule
      const double LIST_LENGTH_FACTOR = 0.25;
      const int MIN_LIST_LENGTH = 10;
      const double MINOR_LIMIT_FACTOR = 0.1;
      const int MIN_MINOR_LIMIT = 3;

      _list_length = std::max( int(LIST_LENGTH_FACTOR *
                                   std::sqrt(double(_search_arc_num))),
                               MIN_LIST_LENGTH );
      _minor_limit = std::max( int(MINOR_LIMIT_FACTOR * _list_length),
                               MIN_MINOR_LIMIT );
      _curr_length = _minor_count = 0;
      _candidates.resize(_list_length);
    }

    /// Find next entering arc
    bool findEnteringArc() {
      Cost min, c;
      int e;
      if (_curr_length > 0 && _minor_count < _minor_limit) {
        // Minor iteration: select the best eligible arc from the
        // current candidate list
        ++_minor_count;
        min = 0;
        for (int i = 0; i < _curr_length; ++i) {
          e = _candidates[i];
          c = _state[e] * (_cost[e] + _pi[_source[e]] - _pi[_target[e]]);
          if (c < min) {
            min = c;
            _in_arc = e;
          }
          else if (c >= 0) {
            _candidates[i--] = _candidates[--_curr_length];
          }
        }
        if (min < 0) return true;
      }

      // Major iteration: build a new candidate list
      min = 0;
      _curr_length = 0;
      for (e = _next_arc; e != _search_arc_num; ++e) {
        c = _state[e] * (_cost[e] + _pi[_source[e]] - _pi[_target[e]]);
        if (c < 0) {
          _candidates[_curr_length++] = e;
          if (c < min) {
            min = c;
            _in_arc = e;
          }
          if (_curr_length == _list_length) goto search_end;
        }
      }
      for (e = 0; e != _next_arc; ++e) {
        c = _state[e] * (_cost[e] + _pi[_source[e]] - _pi[_target[e]]);
        if (c < 0) {
          _candidates[_curr_length++] = e;
          if (c < min) {
            min = c;
            _in_arc = e;
          }
          if (_curr_length == _list_length) goto search_end;
        }
      }
      if (_curr_length == 0) return false;

    search_end:
      _minor_count = 1;
      _next_arc = e;
      return true;
    }

  }; //class CandidateListPivotRule


  // Implementation of the Altering Candidate List pivot rule
  class AlteringListPivotRule
  {
  private:

    // References to the NetworkSimplex class
    const IntVector  &_source;
    const IntVector  &_target;
    const CostVector &_cost;
    const CharVector &_state;
    const CostVector &_pi;
    int &_in_arc;
    int _search_arc_num;

    // Pivot rule data
    int _block_size, _head_length, _curr_length;
    int _next_arc;
    IntVector _candidates;
    CostVector _cand_cost;

    // Functor class to compare arcs during sort of the candidate list
    class SortFunc
    {
    private:
      const CostVector &_map;
    public:
      SortFunc(const CostVector &map) : _map(map) {}
      bool operator()(int left, int right) {
        return _map[left] < _map[right];
      }
    };

    SortFunc _sort_func;

  public:

    // Constructor
    AlteringListPivotRule(NetworkSimplex &ns) :
      _source(ns._source), _target(ns._target),
      _cost(ns._cost), _state(ns._state), _pi(ns._pi),
      _in_arc(ns.in_arc), _search_arc_num(ns._search_arc_num),
      _next_arc(0), _cand_cost(ns._search_arc_num), _sort_func(_cand_cost)
    {
      // The main parameters of the pivot rule
      const double BLOCK_SIZE_FACTOR = 1.0;
      const int MIN_BLOCK_SIZE = 10;
      const double HEAD_LENGTH_FACTOR = 0.01;
      const int MIN_HEAD_LENGTH = 3;

      _block_size = std::max( int(BLOCK_SIZE_FACTOR *
                                  std::sqrt(double(_search_arc_num))),
                              MIN_BLOCK_SIZE );
      _head_length = std::max( int(HEAD_LENGTH_FACTOR * _block_size),
                               MIN_HEAD_LENGTH );
      _candidates.resize(_head_length + _block_size);
      _curr_length = 0;
    }

    // Find next entering arc
    bool findEnteringArc() {
      // Check the current candidate list
      int e;
      Cost c;
      for (int i = 0; i != _curr_length; ++i) {
        e = _candidates[i];
        c = _state[e] * (_cost[e] + _pi[_source[e]] - _pi[_target[e]]);
        if (c < 0) {
          _cand_cost[e] = c;
        } else {
          _candidates[i--] = _candidates[--_curr_length];
        }
      }

      // Extend the list
      int cnt = _block_size;
      int limit = _head_length;

      for (e = _next_arc; e != _search_arc_num; ++e) {
        c = _state[e] * (_cost[e] + _pi[_source[e]] - _pi[_target[e]]);
        if (c < 0) {
          _cand_cost[e] = c;
          _candidates[_curr_length++] = e;
        }
        if (--cnt == 0) {
          if (_curr_length > limit) goto search_end;
          limit = 0;
          cnt = _block_size;
        }
      }
      for (e = 0; e != _next_arc; ++e) {
        c = _state[e] * (_cost[e] + _pi[_source[e]] - _pi[_target[e]]);
        if (c < 0) {
          _cand_cost[e] = c;
          _candidates[_curr_length++] = e;
        }
        if (--cnt == 0) {
          if (_curr_length > limit) goto search_end;
          limit = 0;
          cnt = _block_size;
        }
      }
      if (_curr_length == 0) return false;

    search_end:

      // Perform partial sort operation on the candidate list
      int new_length = std::min(_head_length + 1, _curr_length);
      std::partial_sort(_candidates.begin(), _candidates.begin() + new_length,
                        _candidates.begin() + _curr_length, _sort_func);

      // Select the entering arc and remove it from the list
      _in_arc = _candidates[0];
      _next_arc = e;
      _candidates[0] = _candidates[new_length - 1];
      _curr_length = new_length - 1;
      return true;
    }

  }; //class AlteringListPivotRule

public:

  /// \brief Constructor.
  ///
  /// The constructor of the class.
  ///
  /// \param graph The digraph the algorithm runs on.
  /// \param arc_mixing Indicate if the arcs will be stored in a
  /// mixed order in the internal data structure.
  /// In general, it leads to similar performance as using the original
  /// arc order, but it makes the algorithm more robust and in special
  /// cases, even significantly faster. Therefore, it is enabled by default.
  NetworkSimplex(const GR& graph, bool arc_mixing = true) :
    _graph(graph), _node_id(), _arc_id(),
    _arc_mixing(arc_mixing),
    MAX(std::numeric_limits<Value>::max()),
    INF(std::numeric_limits<Value>::has_infinity ?
        std::numeric_limits<Value>::infinity() : MAX)
  {
    // Check the number types
    LEMON_ASSERT(std::numeric_limits<Value>::is_signed,
      "The flow type of NetworkSimplex must be signed");
    LEMON_ASSERT(std::numeric_limits<Cost>::is_signed,
      "The cost type of NetworkSimplex must be signed");

    // Reset data structures
    reset();
  }

  /// \name Parameters
  /// The parameters of the algorithm can be specified using these
  /// functions.

  /// @{

  /// \brief Set the lower bounds on the arcs.
  ///
  /// This function sets the lower bounds on the arcs.
  /// If it is not used before calling \ref run(), the lower bounds
  /// will be set to zero on all arcs.
  ///
  /// \param map An arc map storing the lower bounds.
  /// Its \c Value type must be convertible to the \c Value type
  /// of the algorithm.
  ///
  /// \return <tt>(*this)</tt>
  template <typename LowerMap>
  NetworkSimplex& lowerMap(LowerMap& map) {
    _has_lower = true;
    for (ArcIt a(_graph); a != INVALID; ++a) {
      _lower[_arc_id[a]] = map[a];
    }
    return *this;
  }

  /// \brief Set the upper bounds (capacities) on the arcs.
  ///
  /// This function sets the upper bounds (capacities) on the arcs.
  /// If it is not used before calling \ref run(), the upper bounds
  /// will be set to \ref INF on all arcs (i.e. the flow value will be
  /// unbounded from above).
  ///
  /// \param map An arc map storing the upper bounds.
  /// Its \c Value type must be convertible to the \c Value type
  /// of the algorithm.
  ///
  /// \return <tt>(*this)</tt>
  template<typename UpperMap>
  NetworkSimplex& upperMap(UpperMap& map) {
    for (ArcIt a(_graph); a != INVALID; ++a) {
      _upper[_arc_id[a]] = map[a];
    }
    return *this;
  }

  /// \brief Set the costs of the arcs.
  ///
  /// This function sets the costs of the arcs.
  /// If it is not used before calling \ref run(), the costs
  /// will be set to \c 1 on all arcs.
  ///
  /// \param map An arc map storing the costs.
  /// Its \c Value type must be convertible to the \c Cost type
  /// of the algorithm.
  ///
  /// \return <tt>(*this)</tt>
  template<typename CostMap>
  NetworkSimplex& costMap(CostMap& map) {
    for (ArcIt a(_graph); a != INVALID; ++a) {
      _cost[_arc_id[a]] = map[a];
    }
    return *this;
  }

  /// \brief Set the supply values of the nodes.
  ///
  /// This function sets the supply values of the nodes.
  /// If neither this function nor \ref stSupply() is used before
  /// calling \ref run(), the supply of each node will be set to zero.
  ///
  /// \param map A node map storing the supply values.
  /// Its \c Value type must be convertible to the \c Value type
  /// of the algorithm.
  ///
  /// \return <tt>(*this)</tt>
  ///
  /// \sa supplyType()
  template<typename SupplyMap>
  NetworkSimplex& supplyMap(SupplyMap& map) {
    for (NodeIt n(_graph); n != INVALID; ++n) {
      _supply[_node_id[n]] = map[n];
    }
    return *this;
  }

  /// \brief Set single source and target nodes and a supply value.
  ///
  /// This function sets a single source node and a single target node
  /// and the required flow value.
  /// If neither this function nor \ref supplyMap() is used before
  /// calling \ref run(), the supply of each node will be set to zero.
  ///
  /// Using this function has the same effect as using \ref supplyMap()
  /// with a map in which \c k is assigned to \c s, \c -k is
  /// assigned to \c t and all other nodes have zero supply value.
  ///
  /// \param s The source node.
  /// \param t The target node.
  /// \param k The required amount of flow from node \c s to node \c t
  /// (i.e. the supply of \c s and the demand of \c t).
  ///
  /// \return <tt>(*this)</tt>
  NetworkSimplex& stSupply(const Node& s, const Node& t, Value k) {
    for (int i = 0; i != _node_num; ++i) {
      _supply[i] = 0;
    }
    _supply[_node_id[s]] =  k;
    _supply[_node_id[t]] = -k;
    return *this;
  }

  /// \brief Set the type of the supply constraints.
  ///
  /// This function sets the type of the supply/demand constraints.
  /// If it is not used before calling \ref run(), the \ref GEQ supply
  /// type will be used.
  ///
  /// For more information, see \ref SupplyType.
  ///
  /// \return <tt>(*this)</tt>
  NetworkSimplex& supplyType(SupplyType supply_type) {
    _stype = supply_type;
    return *this;
  }

  /// @}

  /// \name Execution Control
  /// The algorithm can be executed using \ref run().

  /// @{

  /// \brief Run the algorithm.
  ///
  /// This function runs the algorithm.
  /// The paramters can be specified using functions \ref lowerMap(),
  /// \ref upperMap(), \ref costMap(), \ref supplyMap(), \ref stSupply(),
  /// \ref supplyType().
  /// For example,
  /// \code
  ///   NetworkSimplex<ListDigraph> ns(graph);
  ///   ns.lowerMap(lower).upperMap(upper).costMap(cost)
  ///     .supplyMap(sup).run();
  /// \endcode
  ///
  /// This function can be called more than once. All the given parameters
  /// are kept for the next call, unless \ref resetParams() or \ref reset()
  /// is used, thus only the modified parameters have to be set again.
  /// If the underlying digraph was also modified after the construction
  /// of the class (or the last \ref reset() call), then the \ref reset()
  /// function must be called.
  ///
  /// \param pivot_rule The pivot rule that will be used during the
  /// algorithm. For more information, see \ref PivotRule.
  ///
  /// \return \c INFEASIBLE if no feasible flow exists,
  /// \n \c OPTIMAL if the problem has optimal solution
  /// (i.e. it is feasible and bounded), and the algorithm has found
  /// optimal flow and node potentials (primal and dual solutions),
  /// \n \c UNBOUNDED if the objective function of the problem is
  /// unbounded, i.e. there is a directed cycle having negative total
  /// cost and infinite upper bound.
  ///
  /// \see ProblemType, PivotRule
  /// \see resetParams(), reset()
  ProblemType run(PivotRule pivot_rule = BLOCK_SEARCH) {
    if (!init()) return INFEASIBLE;
    return start(pivot_rule);
  }

  /// \brief Reset all the parameters that have been given before.
  ///
  /// This function resets all the paramaters that have been given
  /// before using functions \ref lowerMap(), \ref upperMap(),
  /// \ref costMap(), \ref supplyMap(), \ref stSupply(), \ref supplyType().
  ///
  /// It is useful for multiple \ref run() calls. Basically, all the given
  /// parameters are kept for the next \ref run() call, unless
  /// \ref resetParams() or \ref reset() is used.
  /// If the underlying digraph was also modified after the construction
  /// of the class or the last \ref reset() call, then the \ref reset()
  /// function must be used, otherwise \ref resetParams() is sufficient.
  ///
  /// For example,
  /// \code
  ///   NetworkSimplex<ListDigraph> ns(graph);
  ///
  ///   // First run
  ///   ns.lowerMap(lower).upperMap(upper).costMap(cost)
  ///     .supplyMap(sup).run();
  ///
  ///   // Run again with modified cost map (resetParams() is not called,
  ///   // so only the cost map have to be set again)
  ///   cost[e] += 100;
  ///   ns.costMap(cost).run();
  ///
  ///   // Run again from scratch using resetParams()
  ///   // (the lower bounds will be set to zero on all arcs)
  ///   ns.resetParams();
  ///   ns.upperMap(capacity).costMap(cost)
  ///     .supplyMap(sup).run();
  /// \endcode
  ///
  /// \return <tt>(*this)</tt>
  ///
  /// \see reset(), run()
  NetworkSimplex& resetParams() {
    for (int i = 0; i != _node_num; ++i) {
      _supply[i] = 0;
    }
    for (int i = 0; i != _arc_num; ++i) {
      _lower[i] = 0;
      _upper[i] = INF;
      _cost[i] = 1;
    }
    _has_lower = false;
    _stype = GEQ;
    return *this;
  }

  /// \brief Reset the internal data structures and all the parameters
  /// that have been given before.
  ///
  /// This function resets the internal data structures and all the
  /// paramaters that have been given before using functions \ref lowerMap(),
  /// \ref upperMap(), \ref costMap(), \ref supplyMap(), \ref stSupply(),
  /// \ref supplyType().
  ///
  /// It is useful for multiple \ref run() calls. Basically, all the given
  /// parameters are kept for the next \ref run() call, unless
  /// \ref resetParams() or \ref reset() is used.
  /// If the underlying digraph was also modified after the construction
  /// of the class or the last \ref reset() call, then the \ref reset()
  /// function must be used, otherwise \ref resetParams() is sufficient.
  ///
  /// See \ref resetParams() for examples.
  ///
  /// \return <tt>(*this)</tt>
  ///
  /// \see resetParams(), run()
  NetworkSimplex& reset() {
    // Resize vectors
    _node_num = _graph.nodeNum();
    _arc_num = _graph.arcNum();
    int all_node_num = _node_num + 1;
    int max_arc_num = _arc_num + 2 * _node_num;

    _source.resize(max_arc_num);
    _target.resize(max_arc_num);

    _lower.resize(_arc_num);
    _upper.resize(_arc_num);
    _cap.resize(max_arc_num);
    _cost.resize(max_arc_num);
    _supply.resize(all_node_num);
    _flow.resize(max_arc_num);
    _pi.resize(all_node_num);

    _parent.resize(all_node_num);
    _pred.resize(all_node_num);
    _pred_dir.resize(all_node_num);
    _thread.resize(all_node_num);
    _rev_thread.resize(all_node_num);
    _succ_num.resize(all_node_num);
    _last_succ.resize(all_node_num);
    _state.resize(max_arc_num);

    // Copy the graph
    int i = 0;
    for (NodeIt n(_graph); n != INVALID; ++n, ++i) {
      _node_id[n] = i;
    }
    if (_arc_mixing && _node_num > 1) {
      // Store the arcs in a mixed order
      const int skip = std::max(_arc_num / _node_num, 3);
      int i = 0, j = 0;
      for (ArcIt a(_graph); a != INVALID; ++a) {
        _arc_id[a] = i;
        _source[i] = _node_id[_graph.source(a)];
        _target[i] = _node_id[_graph.target(a)];
        if ((i += skip) >= _arc_num) i = ++j;
      }
    } else {
      // Store the arcs in the original order
      int i = 0;
      for (ArcIt a(_graph); a != INVALID; ++a, ++i) {
        _arc_id[a] = i;
        _source[i] = _node_id[_graph.source(a)];
        _target[i] = _node_id[_graph.target(a)];
      }
    }

    // Reset parameters
    resetParams();
    return *this;
  }

  /// @}

  /// \name Query Functions
  /// The results of the algorithm can be obtained using these
  /// functions.\n
  /// The \ref run() function must be called before using them.

  /// @{

  /// \brief Return the total cost of the found flow.
  ///
  /// This function returns the total cost of the found flow.
  /// Its complexity is O(m).
  ///
  /// \note The return type of the function can be specified as a
  /// template parameter. For example,
  /// \code
  ///   ns.totalCost<double>();
  /// \endcode
  /// It is useful if the total cost cannot be stored in the \c Cost
  /// type of the algorithm, which is the default return type of the
  /// function.
  ///
  /// \pre \ref run() must be called before using this function.
  template <typename Number>
  Number totalCost() const {
    Number c = 0;
    for (ArcIt a(_graph); a != INVALID; ++a) {
      int i = _arc_id[a];
      c += Number(_flow[i]) * Number(_cost[i]);
    }
    return c;
  }

  Cost totalCost() const {
    return totalCost<Cost>();
  }

  /// \brief Return the flow on the given arc.
  ///
  /// This function returns the flow on the given arc.
  ///
  /// \pre \ref run() must be called before using this function.
  Value flow(const ArcIt& a) {
    return _flow[_arc_id[a]];
  }

  /// \brief Copy the flow values (the primal solution) into the
  /// given map.
  ///
  /// This function copies the flow value on each arc into the given
  /// map. The \c Value type of the algorithm must be convertible to
  /// the \c Value type of the map.
  ///
  /// \pre \ref run() must be called before using this function.
  template <typename FlowMap>
  void flowMap(FlowMap &map) const {
    for (ArcIt a(_graph); a != INVALID; ++a) {
      map.set(a, _flow[_arc_id[a]]);
    }
  }

  /// \brief Return the potential (dual value) of the given node.
  ///
  /// This function returns the potential (dual value) of the
  /// given node.
  ///
  /// \pre \ref run() must be called before using this function.
  Cost potential(const Node& n) const {
    return _pi[_node_id[n]];
  }

  /// \brief Copy the potential values (the dual solution) into the
  /// given map.
  ///
  /// This function copies the potential (dual value) of each node
  /// into the given map.
  /// The \c Cost type of the algorithm must be convertible to the
  /// \c Value type of the map.
  ///
  /// \pre \ref run() must be called before using this function.
  template <typename PotentialMap>
  void potentialMap(PotentialMap &map) const {
    for (NodeIt n(_graph); n != INVALID; ++n) {
      map.set(n, _pi[_node_id[n]]);
    }
  }

  /// @}

private:

  // Initialize internal data structures
  bool init() {
    if (_node_num == 0) return false;

    // Check the sum of supply values
    _sum_supply = 0;
    for (int i = 0; i != _node_num; ++i) {
      _sum_supply += _supply[i];
    }
    if ( !((_stype == GEQ && _sum_supply <= 0) ||
           (_stype == LEQ && _sum_supply >= 0)) ) return false;

    // Check lower and upper bounds
    LEMON_DEBUG(checkBoundMaps(),
        "Upper bounds must be greater or equal to the lower bounds");

    // Remove non-zero lower bounds
    if (_has_lower) {
      for (int i = 0; i != _arc_num; ++i) {
        Value c = _lower[i];
        if (c >= 0) {
          _cap[i] = _upper[i] < MAX ? _upper[i] - c : INF;
        } else {
          _cap[i] = _upper[i] < MAX + c ? _upper[i] - c : INF;
        }
        _supply[_source[i]] -= c;
        _supply[_target[i]] += c;
      }
    } else {
      for (int i = 0; i != _arc_num; ++i) {
        _cap[i] = _upper[i];
      }
    }

    // Initialize artifical cost
    Cost ART_COST;
    if (std::numeric_limits<Cost>::is_exact) {
      ART_COST = std::numeric_limits<Cost>::max() / 2 + 1;
    } else {
      ART_COST = 0;
      for (int i = 0; i != _arc_num; ++i) {
        if (_cost[i] > ART_COST) ART_COST = _cost[i];
      }
      ART_COST = (ART_COST + 1) * _node_num;
    }

    // Initialize arc maps
    for (int i = 0; i != _arc_num; ++i) {
      _flow[i] = 0;
      _state[i] = STATE_LOWER;
    }

    // Set data for the artificial root node
    _root = _node_num;
    _parent[_root] = -1;
    _pred[_root] = -1;
    _thread[_root] = 0;
    _rev_thread[0] = _root;
    _succ_num[_root] = _node_num + 1;
    _last_succ[_root] = _root - 1;
    _supply[_root] = -_sum_supply;
    _pi[_root] = 0;

    // Add artificial arcs and initialize the spanning tree data structure
    if (_sum_supply == 0) {
      // EQ supply constraints
      _search_arc_num = _arc_num;
      _all_arc_num = _arc_num + _node_num;
      for (int u = 0, e = _arc_num; u != _node_num; ++u, ++e) {
        _parent[u] = _root;
        _pred[u] = e;
        _thread[u] = u + 1;
        _rev_thread[u + 1] = u;
        _succ_num[u] = 1;
        _last_succ[u] = u;
        _cap[e] = INF;
        _state[e] = STATE_TREE;
        if (_supply[u] >= 0) {
          _pred_dir[u] = DIR_UP;
          _pi[u] = 0;
          _source[e] = u;
          _target[e] = _root;
          _flow[e] = _supply[u];
          _cost[e] = 0;
        } else {
          _pred_dir[u] = DIR_DOWN;
          _pi[u] = ART_COST;
          _source[e] = _root;
          _target[e] = u;
          _flow[e] = -_supply[u];
          _cost[e] = ART_COST;
        }
      }
    }
    else if (_sum_supply > 0) {
      // LEQ supply constraints
      _search_arc_num = _arc_num + _node_num;
      int f = _arc_num + _node_num;
      for (int u = 0, e = _arc_num; u != _node_num; ++u, ++e) {
        _parent[u] = _root;
        _thread[u] = u + 1;
        _rev_thread[u + 1] = u;
        _succ_num[u] = 1;
        _last_succ[u] = u;
        if (_supply[u] >= 0) {
          _pred_dir[u] = DIR_UP;
          _pi[u] = 0;
          _pred[u] = e;
          _source[e] = u;
          _target[e] = _root;
          _cap[e] = INF;
          _flow[e] = _supply[u];
          _cost[e] = 0;
          _state[e] = STATE_TREE;
        } else {
          _pred_dir[u] = DIR_DOWN;
          _pi[u] = ART_COST;
          _pred[u] = f;
          _source[f] = _root;
          _target[f] = u;
          _cap[f] = INF;
          _flow[f] = -_supply[u];
          _cost[f] = ART_COST;
          _state[f] = STATE_TREE;
          _source[e] = u;
          _target[e] = _root;
          _cap[e] = INF;
          _flow[e] = 0;
          _cost[e] = 0;
          _state[e] = STATE_LOWER;
          ++f;
        }
      }
      _all_arc_num = f;
    }
    else {
      // GEQ supply constraints
      _search_arc_num = _arc_num + _node_num;
      int f = _arc_num + _node_num;
      for (int u = 0, e = _arc_num; u != _node_num; ++u, ++e) {
        _parent[u] = _root;
        _thread[u] = u + 1;
        _rev_thread[u + 1] = u;
        _succ_num[u] = 1;
        _last_succ[u] = u;
        if (_supply[u] <= 0) {
          _pred_dir[u] = DIR_DOWN;
          _pi[u] = 0;
          _pred[u] = e;
          _source[e] = _root;
          _target[e] = u;
          _cap[e] = INF;
          _flow[e] = -_supply[u];
          _cost[e] = 0;
          _state[e] = STATE_TREE;
        } else {
          _pred_dir[u] = DIR_UP;
          _pi[u] = -ART_COST;
          _pred[u] = f;
          _source[f] = u;
          _target[f] = _root;
          _cap[f] = INF;
          _flow[f] = _supply[u];
          _state[f] = STATE_TREE;
          _cost[f] = ART_COST;
          _source[e] = _root;
          _target[e] = u;
          _cap[e] = INF;
          _flow[e] = 0;
          _cost[e] = 0;
          _state[e] = STATE_LOWER;
          ++f;
        }
      }
      _all_arc_num = f;
    }

    return true;
  }

  // Check if the upper bound is greater than or equal to the lower bound
  // on each arc.
  bool checkBoundMaps() {
    for (int j = 0; j != _arc_num; ++j) {
      if (_upper[j] < _lower[j]) return false;
    }
    return true;
  }

  // Find the join node
  void findJoinNode() {
    int u = _source[in_arc];
    int v = _target[in_arc];
    while (u != v) {
      if (_succ_num[u] < _succ_num[v]) {
        u = _parent[u];
      } else {
        v = _parent[v];
      }
    }
    join = u;
  }

  // Find the leaving arc of the cycle and returns true if the
  // leaving arc is not the same as the entering arc
  bool findLeavingArc() {
    // Initialize first and second nodes according to the direction
    // of the cycle
    int first, second;
    if (_state[in_arc] == STATE_LOWER) {
      first  = _source[in_arc];
      second = _target[in_arc];
    } else {
      first  = _target[in_arc];
      second = _source[in_arc];
    }
    delta = _cap[in_arc];
    int result = 0;
    Value c, d;
    int e;

    // Search the cycle form the first node to the join node
    for (int u = first; u != join; u = _parent[u]) {
      e = _pred[u];
      d = _flow[e];
      if (_pred_dir[u] == DIR_DOWN) {
        c = _cap[e];
        d = c >= MAX ? INF : c - d;
      }
      if (d < delta) {
        delta = d;
        u_out = u;
        result = 1;
      }
    }

    // Search the cycle form the second node to the join node
    for (int u = second; u != join; u = _parent[u]) {
      e = _pred[u];
      d = _flow[e];
      if (_pred_dir[u] == DIR_UP) {
        c = _cap[e];
        d = c >= MAX ? INF : c - d;
      }
      if (d <= delta) {
        delta = d;
        u_out = u;
        result = 2;
      }
    }

    if (result == 1) {
      u_in = first;
      v_in = second;
    } else {
      u_in = second;
      v_in = first;
    }
    return result != 0;
  }

  // Change _flow and _state vectors
  void changeFlow(bool change) {
    // Augment along the cycle
    if (delta > 0) {
      Value val = _state[in_arc] * delta;
      _flow[in_arc] += val;
      for (int u = _source[in_arc]; u != join; u = _parent[u]) {
        _flow[_pred[u]] -= _pred_dir[u] * val;
      }
      for (int u = _target[in_arc]; u != join; u = _parent[u]) {
        _flow[_pred[u]] += _pred_dir[u] * val;
      }
    }
    // Update the state of the entering and leaving arcs
    if (change) {
      _state[in_arc] = STATE_TREE;
      _state[_pred[u_out]] =
        (_flow[_pred[u_out]] == 0) ? STATE_LOWER : STATE_UPPER;
    } else {
      _state[in_arc] = -_state[in_arc];
    }
  }

  // Update the tree structure
  void updateTreeStructure() {
    int old_rev_thread = _rev_thread[u_out];
    int old_succ_num = _succ_num[u_out];
    int old_last_succ = _last_succ[u_out];
    v_out = _parent[u_out];

    // Check if u_in and u_out coincide
    if (u_in == u_out) {
      // Update _parent, _pred, _pred_dir
      _parent[u_in] = v_in;
      _pred[u_in] = in_arc;
      _pred_dir[u_in] = u_in == _source[in_arc] ? DIR_UP : DIR_DOWN;

      // Update _thread and _rev_thread
      if (_thread[v_in] != u_out) {
        int after = _thread[old_last_succ];
        _thread[old_rev_thread] = after;
        _rev_thread[after] = old_rev_thread;
        after = _thread[v_in];
        _thread[v_in] = u_out;
        _rev_thread[u_out] = v_in;
        _thread[old_last_succ] = after;
        _rev_thread[after] = old_last_succ;
      }
    } else {
      // Handle the case when old_rev_thread equals to v_in
      // (it also means that join and v_out coincide)
      int thread_continue = old_rev_thread == v_in ?
        _thread[old_last_succ] : _thread[v_in];

      // Update _thread and _parent along the stem nodes (i.e. the nodes
      // between u_in and u_out, whose parent have to be changed)
      int stem = u_in;              // the current stem node
      int par_stem = v_in;          // the new parent of stem
      int next_stem;                // the next stem node
      int last = _last_succ[u_in];  // the last successor of stem
      int before, after = _thread[last];
      _thread[v_in] = u_in;
      _dirty_revs.clear();
      _dirty_revs.push_back(v_in);
      while (stem != u_out) {
        // Insert the next stem node into the thread list
        next_stem = _parent[stem];
        _thread[last] = next_stem;
        _dirty_revs.push_back(last);

        // Remove the subtree of stem from the thread list
        before = _rev_thread[stem];
        _thread[before] = after;
        _rev_thread[after] = before;

        // Change the parent node and shift stem nodes
        _parent[stem] = par_stem;
        par_stem = stem;
        stem = next_stem;

        // Update last and after
        last = _last_succ[stem] == _last_succ[par_stem] ?
          _rev_thread[par_stem] : _last_succ[stem];
        after = _thread[last];
      }
      _parent[u_out] = par_stem;
      _thread[last] = thread_continue;
      _rev_thread[thread_continue] = last;
      _last_succ[u_out] = last;

      // Remove the subtree of u_out from the thread list except for
      // the case when old_rev_thread equals to v_in
      if (old_rev_thread != v_in) {
        _thread[old_rev_thread] = after;
        _rev_thread[after] = old_rev_thread;
      }

      // Update _rev_thread using the new _thread values
      for (int i = 0; i != int(_dirty_revs.size()); ++i) {
        int u = _dirty_revs[i];
        _rev_thread[_thread[u]] = u;
      }

      // Update _pred, _pred_dir, _last_succ and _succ_num for the
      // stem nodes from u_out to u_in
      int tmp_sc = 0, tmp_ls = _last_succ[u_out];
      for (int u = u_out, p = _parent[u]; u != u_in; u = p, p = _parent[u]) {
        _pred[u] = _pred[p];
        _pred_dir[u] = -_pred_dir[p];
        tmp_sc += _succ_num[u] - _succ_num[p];
        _succ_num[u] = tmp_sc;
        _last_succ[p] = tmp_ls;
      }
      _pred[u_in] = in_arc;
      _pred_dir[u_in] = u_in == _source[in_arc] ? DIR_UP : DIR_DOWN;
      _succ_num[u_in] = old_succ_num;
    }

    // Update _last_succ from v_in towards the root
    int up_limit_out = _last_succ[join] == v_in ? join : -1;
    int last_succ_out = _last_succ[u_out];
    for (int u = v_in; u != -1 && _last_succ[u] == v_in; u = _parent[u]) {
      _last_succ[u] = last_succ_out;
    }

    // Update _last_succ from v_out towards the root
    if (join != old_rev_thread && v_in != old_rev_thread) {
      for (int u = v_out; u != up_limit_out && _last_succ[u] == old_last_succ;
           u = _parent[u]) {
        _last_succ[u] = old_rev_thread;
      }
    }
    else if (last_succ_out != old_last_succ) {
      for (int u = v_out; u != up_limit_out && _last_succ[u] == old_last_succ;
           u = _parent[u]) {
        _last_succ[u] = last_succ_out;
      }
    }

    // Update _succ_num from v_in to join
    for (int u = v_in; u != join; u = _parent[u]) {
      _succ_num[u] += old_succ_num;
    }
    // Update _succ_num from v_out to join
    for (int u = v_out; u != join; u = _parent[u]) {
      _succ_num[u] -= old_succ_num;
    }
  }

  // Update potentials in the subtree that has been moved
  void updatePotential() {
    Cost sigma = _pi[v_in] - _pi[u_in] -
                 _pred_dir[u_in] * _cost[in_arc];
    int end = _thread[_last_succ[u_in]];
    for (int u = u_in; u != end; u = _thread[u]) {
      _pi[u] += sigma;
    }
  }

  // Heuristic initial pivots
  bool initialPivots() {
    Value curr, total = 0;
    std::vector<Node> supply_nodes, demand_nodes;
    for (NodeIt u(_graph); u != INVALID; ++u) {
      curr = _supply[_node_id[u]];
      if (curr > 0) {
        total += curr;
        supply_nodes.push_back(u);
      }
      else if (curr < 0) {
        demand_nodes.push_back(u);
      }
    }
    if (_sum_supply > 0) total -= _sum_supply;
    if (total <= 0) return true;

    IntVector arc_vector;
    if (_sum_supply >= 0) {
      if (supply_nodes.size() == 1 && demand_nodes.size() == 1) {
        // Perform a reverse graph search from the sink to the source
        std::set<Node> reached;
        Node s = supply_nodes[0], t = demand_nodes[0];
        std::vector<Node> stack;
        reached.insert(t);
        stack.push_back(t);
        while (!stack.empty()) {
          Node u, v = stack.back();
          stack.pop_back();
          if (v == s) break;
          for (InArcIt a(_graph, v); a != INVALID; ++a) {
            if (reached.count(u = _graph.source(a))) continue;
            int j = _arc_id[a];
            if (_cap[j] >= total) {
              arc_vector.push_back(j);
              reached.insert(u);
              stack.push_back(u);
            }
          }
        }
      } else {
        // Find the min. cost incoming arc for each demand node
        for (int i = 0; i != int(demand_nodes.size()); ++i) {
          Node v = demand_nodes[i];
          Cost c, min_cost = std::numeric_limits<Cost>::max();
          Arc min_arc = INVALID;
          for (InArcIt a(_graph, v); a != INVALID; ++a) {
            c = _cost[_arc_id[a]];
            if (c < min_cost) {
              min_cost = c;
              min_arc = a;
            }
          }
          if (min_arc != INVALID) {
            arc_vector.push_back(_arc_id[min_arc]);
          }
        }
      }
    } else {
      // Find the min. cost outgoing arc for each supply node
      for (int i = 0; i != int(supply_nodes.size()); ++i) {
        Node u = supply_nodes[i];
        Cost c, min_cost = std::numeric_limits<Cost>::max();
        Arc min_arc = INVALID;
        for (OutArcIt a(_graph, u); a != INVALID; ++a) {
          c = _cost[_arc_id[a]];
          if (c < min_cost) {
            min_cost = c;
            min_arc = a;
          }
        }
        if (min_arc != INVALID) {
          arc_vector.push_back(_arc_id[min_arc]);
        }
      }
    }

    // Perform heuristic initial pivots
    for (int i = 0; i != int(arc_vector.size()); ++i) {
      in_arc = arc_vector[i];
      if (_state[in_arc] * (_cost[in_arc] + _pi[_source[in_arc]] -
          _pi[_target[in_arc]]) >= 0) continue;
      findJoinNode();
      bool change = findLeavingArc();
      if (delta >= MAX) return false;
      changeFlow(change);
      if (change) {
        updateTreeStructure();
        updatePotential();
      }
    }
    return true;
  }

  // Execute the algorithm
  ProblemType start(PivotRule pivot_rule) {
    // Select the pivot rule implementation
    switch (pivot_rule) {
      case FIRST_ELIGIBLE:
        return start<FirstEligiblePivotRule>();
      case BEST_ELIGIBLE:
        return start<BestEligiblePivotRule>();
      case BLOCK_SEARCH:
        return start<BlockSearchPivotRule>();
      case CANDIDATE_LIST:
        return start<CandidateListPivotRule>();
      case ALTERING_LIST:
        return start<AlteringListPivotRule>();
    }
    return INFEASIBLE; // avoid warning
  }

  template <typename PivotRuleImpl>
  ProblemType start() {
    PivotRuleImpl pivot(*this);

    // Perform heuristic initial pivots
    if (!initialPivots()) return UNBOUNDED;

    // Execute the Network Simplex algorithm
    while (pivot.findEnteringArc()) {
      findJoinNode();
      bool change = findLeavingArc();
      if (delta >= MAX) return UNBOUNDED;
      changeFlow(change);
      if (change) {
        updateTreeStructure();
        updatePotential();
      }
    }

    // Check feasibility
    for (int e = _search_arc_num; e != _all_arc_num; ++e) {
      if (_flow[e] != 0) return INFEASIBLE;
    }

    // Transform the solution and the supply map to the original form
    if (_has_lower) {
      for (int i = 0; i != _arc_num; ++i) {
        Value c = _lower[i];
        if (c != 0) {
          _flow[i] += c;
          _supply[_source[i]] += c;
          _supply[_target[i]] -= c;
        }
      }
    }

    // Shift potentials to meet the requirements of the GEQ/LEQ type
    // optimality conditions
    if (_sum_supply == 0) {
      if (_stype == GEQ) {
        Cost max_pot = -std::numeric_limits<Cost>::max();
        for (int i = 0; i != _node_num; ++i) {
          if (_pi[i] > max_pot) max_pot = _pi[i];
        }
        if (max_pot > 0) {
          for (int i = 0; i != _node_num; ++i)
            _pi[i] -= max_pot;
        }
      } else {
        Cost min_pot = std::numeric_limits<Cost>::max();
        for (int i = 0; i != _node_num; ++i) {
          if (_pi[i] < min_pot) min_pot = _pi[i];
        }
        if (min_pot < 0) {
          for (int i = 0; i != _node_num; ++i)
            _pi[i] -= min_pot;
        }
      }
    }

    return OPTIMAL;
  }

}; //class NetworkSimplex

class Digraph {
protected:
  struct NodeT {
    int first_in, first_out;
    NodeT() {}
  };
  struct ArcT {
    int target, source, next_in, next_out;
    ArcT() {}
  };

  std::vector<NodeT> nodes;
  std::vector<ArcT> arcs;

public:
  class Node;
  class Arc;

  Digraph() : nodes(), arcs() {}
  Digraph(const Digraph &_g)
      : nodes(_g.nodes), arcs(_g.arcs) {}

  int nodeNum() const { return nodes.size(); }
  int arcNum() const { return arcs.size(); }

  int maxNodeId() const { return nodes.size() - 1; }
  int maxArcId() const { return arcs.size() - 1; }

  Node addNode() {
    int n = nodes.size();
    nodes.push_back(NodeT());
    nodes[n].first_in = -1;
    nodes[n].first_out = -1;
    return Node(n);
  }

  Arc addArc(Node u, Node v) {
    int n = arcs.size();
    arcs.push_back(ArcT());
    arcs[n].source = u._id;
    arcs[n].target = v._id;
    arcs[n].next_out = nodes[u._id].first_out;
    arcs[n].next_in = nodes[v._id].first_in;
    nodes[u._id].first_out = nodes[v._id].first_in = n;

    return Arc(n);
  }

  void clear() {
    arcs.clear();
    nodes.clear();
  }

  Node source(Arc a) const { return Node(arcs[a._id].source); }
  Node target(Arc a) const { return Node(arcs[a._id].target); }

  static int id(Node v) { return v._id; }
  static int id(Arc a) { return a._id; }

  static Node nodeFromId(int id) { return Node(id); }
  static Arc arcFromId(int id) { return Arc(id); }

  bool valid(Node n) const {
    return n._id >= 0 && n._id < static_cast<int>(nodes.size());
  }
  bool valid(Arc a) const {
    return a._id >= 0 && a._id < static_cast<int>(arcs.size());
  }

  class Node {
    friend class Digraph;

  protected:
    int _id;
    explicit Node(int id) : _id(id) {}

  public:
    Node() {}
    Node(Invalid) : _id(-1) {}
    bool operator==(const Node i) const { return _id == i._id; }
    bool operator!=(const Node i) const { return _id != i._id; }
    bool operator<(const Node i) const { return _id < i._id; }
  };

  class Arc {
    friend class Digraph;

  protected:
    int _id;
    explicit Arc(int id) : _id(id) {}

  public:
    Arc() {}
    Arc(Invalid) : _id(-1) {}
    bool operator==(const Arc i) const { return _id == i._id; }
    bool operator!=(const Arc i) const { return _id != i._id; }
    bool operator<(const Arc i) const { return _id < i._id; }
  };

  void first(Node &node) const { node._id = nodes.size() - 1; }

  static void next(Node &node) { --node._id; }

  void first(Arc &arc) const { arc._id = arcs.size() - 1; }

  static void next(Arc &arc) { --arc._id; }

  void firstOut(Arc &arc, const Node &node) const {
    arc._id = nodes[node._id].first_out;
  }

  void nextOut(Arc &arc) const { arc._id = arcs[arc._id].next_out; }

  void firstIn(Arc &arc, const Node &node) const {
    arc._id = nodes[node._id].first_in;
  }

  void nextIn(Arc &arc) const { arc._id = arcs[arc._id].next_in; }

  /// Reserve memory for nodes.

  /// Using this function, it is possible to avoid superfluous memory
  /// allocation: if you know that the digraph you want to build will
  /// be large (e.g. it will contain millions of nodes and/or arcs),
  /// then it is worth reserving space for this amount before starting
  /// to build the digraph.
  /// \sa reserveArc()
  void reserveNode(int n) { nodes.reserve(n); };

  /// Reserve memory for arcs.

  /// Using this function, it is possible to avoid superfluous memory
  /// allocation: if you know that the digraph you want to build will
  /// be large (e.g. it will contain millions of nodes and/or arcs),
  /// then it is worth reserving space for this amount before starting
  /// to build the digraph.
  /// \sa reserveNode()
  void reserveArc(int m) { arcs.reserve(m); };

  class NodeIt : public Node {
    const Digraph *_digraph;

  public:
    NodeIt() {}

    NodeIt(Invalid i) : Node(i) {}

    explicit NodeIt(const Digraph &digraph) : _digraph(&digraph) {
      _digraph->first(static_cast<Node &>(*this));
    }

    NodeIt(const Digraph &digraph, const Node &node)
        : Node(node), _digraph(&digraph) {}

    NodeIt &operator++() {
      _digraph->next(*this);
      return *this;
    }
  };

  class ArcIt : public Arc {
    const Digraph *_digraph;

  public:
    ArcIt() {}

    ArcIt(Invalid i) : Arc(i) {}

    explicit ArcIt(const Digraph &digraph) : _digraph(&digraph) {
      _digraph->first(static_cast<Arc &>(*this));
    }

    ArcIt(const Digraph &digraph, const Arc &arc)
        : Arc(arc), _digraph(&digraph) {}

    ArcIt &operator++() {
      _digraph->next(*this);
      return *this;
    }
  };

  class OutArcIt : public Arc {
    const Digraph *_digraph;

  public:
    OutArcIt() {}

    OutArcIt(Invalid i) : Arc(i) {}

    OutArcIt(const Digraph &digraph, const Node &node)
        : _digraph(&digraph) {
      _digraph->firstOut(*this, node);
    }

    OutArcIt(const Digraph &digraph, const Arc &arc)
        : Arc(arc), _digraph(&digraph) {}

    OutArcIt &operator++() {
      _digraph->nextOut(*this);
      return *this;
    }
  };

  class InArcIt : public Arc {
    const Digraph *_digraph;

  public:
    InArcIt() {}

    InArcIt(Invalid i) : Arc(i) {}

    InArcIt(const Digraph &digraph, const Node &node)
        : _digraph(&digraph) {
      _digraph->firstIn(*this, node);
    }

    InArcIt(const Digraph &digraph, const Arc &arc)
        : Arc(arc), _digraph(&digraph) {}

    InArcIt &operator++() {
      _digraph->nextIn(*this);
      return *this;
    }
  };
}; // end class Digraph

} // end namespace lemon

namespace llvm {
namespace bolt {

using namespace lemon;

namespace {

// Edge Weight Inference Heuristic
//
// We start by maintaining the invariant used in LBR mode where the sum of
// pred edges count is equal to the block execution count. This loop will set
// pred edges count by balancing its own execution count in different pred
// edges. The weight of each edge is guessed by looking at how hot each pred
// block is (in terms of samples).
// There are two caveats in this approach. One is for critical edges and the
// other is for self-referencing blocks (loops of 1 BB). For critical edges,
// we can't infer the hotness of them based solely on pred BBs execution
// count. For each critical edge we look at the pred BB, then look at its
// succs to adjust its weight.
//
//    [ 60  ]       [ 25 ]
//       |      \     |
//    [ 10  ]       [ 75 ]
//
// The illustration above shows a critical edge \. We wish to adjust bb count
// 60 to 50 to properly determine the weight of the critical edge to be
// 50 / 75.
// For self-referencing edges, we attribute its weight by subtracting the
// current BB execution count by the sum of predecessors count if this result
// is non-negative.
using EdgeWeightMap =
    DenseMap<std::pair<const BinaryBasicBlock *, const BinaryBasicBlock *>,
             double>;

template <class NodeT>
void updateEdgeWeight(EdgeWeightMap &EdgeWeights, const BinaryBasicBlock *A,
                      const BinaryBasicBlock *B, double Weight);

template <>
void updateEdgeWeight<BinaryBasicBlock *>(
    EdgeWeightMap &EdgeWeights, const BinaryBasicBlock *A,
    const BinaryBasicBlock *B, double Weight) {
  EdgeWeights[std::make_pair(A, B)] = Weight;
  return;
}

template <>
void updateEdgeWeight<Inverse<BinaryBasicBlock *>>(
    EdgeWeightMap &EdgeWeights, const BinaryBasicBlock *A,
    const BinaryBasicBlock *B, double Weight) {
  EdgeWeights[std::make_pair(B, A)] = Weight;
  return;
}

template <class NodeT>
void computeEdgeWeights(BinaryBasicBlock *BB, EdgeWeightMap &EdgeWeights) {
  typedef GraphTraits<NodeT> GraphT;
  typedef GraphTraits<Inverse<NodeT> > InvTraits;

  double TotalChildrenCount{0.0};
  SmallVector<double, 4> ChildrenExecCount;
  // First pass computes total children execution count that directly
  // contribute to this BB.
  for (typename GraphT::ChildIteratorType CI = GraphT::child_begin(BB),
         E = GraphT::child_end(BB); CI != E; ++CI) {
    typename GraphT::NodeRef Child = *CI;
    double ChildExecCount = Child->getExecutionCount();
    // Is self-reference?
    if (Child == BB) {
      ChildExecCount = 0.0; // will fill this in second pass
    } else if (GraphT::child_end(BB) - GraphT::child_begin(BB) > 1 &&
               InvTraits::child_end(Child) - InvTraits::child_begin(Child) >
                   1) {
      // Handle critical edges. This will cause a skew towards crit edges, but
      // it is a quick solution.
      double CritWeight = 0.0;
      uint64_t Denominator = 0;
      for (typename InvTraits::ChildIteratorType
               II = InvTraits::child_begin(Child),
               IE = InvTraits::child_end(Child);
           II != IE; ++II) {
        typename GraphT::NodeRef N = *II;
        Denominator += N->getExecutionCount();
        if (N != BB) {
          continue;
        }
        CritWeight = N->getExecutionCount();
      }
      if (Denominator)
        CritWeight /= static_cast<double>(Denominator);
      ChildExecCount *= CritWeight;
    }
    ChildrenExecCount.push_back(ChildExecCount);
    TotalChildrenCount += ChildExecCount;
  }
  // Second pass fixes the weight of a possible self-reference edge
  uint32_t ChildIndex{0};
  for (typename GraphT::ChildIteratorType CI = GraphT::child_begin(BB),
         E = GraphT::child_end(BB); CI != E; ++CI) {
    typename GraphT::NodeRef Child = *CI;
    if (Child != BB) {
      ++ChildIndex;
      continue;
    }
    if (static_cast<double>(BB->getExecutionCount()) > TotalChildrenCount) {
      ChildrenExecCount[ChildIndex] =
          BB->getExecutionCount() - TotalChildrenCount;
      TotalChildrenCount += ChildrenExecCount[ChildIndex];
    }
    break;
  }
  // Third pass finally assigns weights to edges
  ChildIndex = 0;
  for (typename GraphT::ChildIteratorType CI = GraphT::child_begin(BB),
         E = GraphT::child_end(BB); CI != E; ++CI) {
    typename GraphT::NodeRef Child = *CI;
    double Weight = 1 / (GraphT::child_end(BB) - GraphT::child_begin(BB));
    if (TotalChildrenCount != 0.0)
      Weight = ChildrenExecCount[ChildIndex] / TotalChildrenCount;
    updateEdgeWeight<NodeT>(EdgeWeights, BB, Child, Weight);
    ++ChildIndex;
  }
}

template<class NodeT>
void computeEdgeWeights(BinaryFunction &BF, EdgeWeightMap &EdgeWeights) {
  for (auto &BB : BF) {
    computeEdgeWeights<NodeT>(&BB, EdgeWeights);
  }
}

/// Make BB count match the sum of all incoming edges. If AllEdges is true,
/// make it match max(SumPredEdges, SumSuccEdges).
void recalculateBBCounts(BinaryFunction &BF, bool AllEdges) {
  for (auto &BB : BF) {
    uint64_t TotalPredsEWeight{0};
    for (auto Pred : BB.predecessors()) {
      TotalPredsEWeight += Pred->getBranchInfo(BB).Count;
    }

    if (TotalPredsEWeight > BB.getExecutionCount()) {
      BB.setExecutionCount(TotalPredsEWeight);
    }

    if (!AllEdges)
      continue;

    uint64_t TotalSuccsEWeight{0};
    for (auto &BI : BB.branch_info()) {
      TotalSuccsEWeight += BI.Count;
    }

    if (TotalSuccsEWeight > BB.getExecutionCount()) {
      BB.setExecutionCount(TotalSuccsEWeight);
    }
  }
}

// This is our main edge count guessing heuristic. Look at predecessors and
// assign a proportionally higher count to pred edges coming from blocks with
// a higher execution count in comparison with the other predecessor blocks,
// making SumPredEdges match the current BB count.
// If "UseSucc" is true, apply the same logic to successor edges as well. Since
// some successor edges may already have assigned a count, only update it if the
// new count is higher.
void guessEdgeByRelHotness(BinaryFunction &BF, bool UseSucc,
                           EdgeWeightMap &PredEdgeWeights,
                           EdgeWeightMap &SuccEdgeWeights) {
  for (auto &BB : BF) {
    for (auto Pred : BB.predecessors()) {
      double RelativeExec = PredEdgeWeights[std::make_pair(Pred, &BB)];
      RelativeExec *= BB.getExecutionCount();
      auto &BI = Pred->getBranchInfo(BB);
      if (static_cast<uint64_t>(RelativeExec) > BI.Count)
        BI.Count = static_cast<uint64_t>(RelativeExec);
    }

    if (!UseSucc)
      continue;

    auto BI = BB.branch_info_begin();
    for (auto Succ : BB.successors()) {
      double RelativeExec = SuccEdgeWeights[std::make_pair(&BB, Succ)];
      RelativeExec *= BB.getExecutionCount();
      if (static_cast<uint64_t>(RelativeExec) > BI->Count)
        BI->Count = static_cast<uint64_t>(RelativeExec);
      ++BI;
    }
  }
}

using ArcSet =
    DenseSet<std::pair<const BinaryBasicBlock *, const BinaryBasicBlock *>>;

/// Predecessor edges version of guessEdgeByIterativeApproach. GuessedArcs has
/// all edges we already established their count. Try to guess the count of
/// the remaining edge, if there is only one to guess, and return true if we
/// were able to guess.
bool guessPredEdgeCounts(BinaryBasicBlock *BB, ArcSet &GuessedArcs) {
  if (BB->pred_size() == 0)
    return false;

  uint64_t TotalPredCount{0};
  unsigned NumGuessedEdges{0};
  for (auto Pred : BB->predecessors()) {
    if (GuessedArcs.count(std::make_pair(Pred, BB)))
      ++NumGuessedEdges;
    TotalPredCount += Pred->getBranchInfo(*BB).Count;
  }

  if (NumGuessedEdges != BB->pred_size() - 1)
    return false;

  int64_t Guessed =
      static_cast<int64_t>(BB->getExecutionCount()) - TotalPredCount;
  if (Guessed < 0)
    Guessed = 0;

  for (auto Pred : BB->predecessors()) {
    if (GuessedArcs.count(std::make_pair(Pred, BB)))
      continue;

    Pred->getBranchInfo(*BB).Count = Guessed;
    return true;
  }
  llvm_unreachable("Expected unguessed arc");
}

/// Successor edges version of guessEdgeByIterativeApproach. GuessedArcs has
/// all edges we already established their count. Try to guess the count of
/// the remaining edge, if there is only one to guess, and return true if we
/// were able to guess.
bool guessSuccEdgeCounts(BinaryBasicBlock *BB, ArcSet &GuessedArcs) {
  if (BB->succ_size() == 0)
    return false;

  uint64_t TotalSuccCount{0};
  unsigned NumGuessedEdges{0};
  auto BI = BB->branch_info_begin();
  for (auto Succ : BB->successors()) {
    if (GuessedArcs.count(std::make_pair(BB, Succ)))
      ++NumGuessedEdges;
    TotalSuccCount += BI->Count;
    ++BI;
  }

  if (NumGuessedEdges != BB->succ_size() - 1)
    return false;

  int64_t Guessed =
      static_cast<int64_t>(BB->getExecutionCount()) - TotalSuccCount;
  if (Guessed < 0)
    Guessed = 0;

  BI = BB->branch_info_begin();
  for (auto Succ : BB->successors()) {
    if (GuessedArcs.count(std::make_pair(BB, Succ))) {
      ++BI;
      continue;
    }

    BI->Count = Guessed;
    GuessedArcs.insert(std::make_pair(BB, Succ));
    return true;
  }
  llvm_unreachable("Expected unguessed arc");
}

/// Guess edge count whenever we have only one edge (pred or succ) left
/// to guess. Then make its count equal to BB count minus all other edge
/// counts we already know their count. Repeat this until there is no
/// change.
void guessEdgeByIterativeApproach(BinaryFunction &BF) {
  ArcSet KnownArcs;
  bool Changed{false};

  do {
    Changed = false;
    for (auto &BB : BF) {
      if (guessPredEdgeCounts(&BB, KnownArcs)) Changed = true;
      if (guessSuccEdgeCounts(&BB, KnownArcs)) Changed = true;
    }
  } while (Changed);

  // Guess count for non-inferred edges
  for (auto &BB : BF) {
    for (auto Pred : BB.predecessors()) {
      if (KnownArcs.count(std::make_pair(Pred, &BB)))
        continue;
      auto &BI = Pred->getBranchInfo(BB);
      BI.Count =
        std::min(Pred->getExecutionCount(), BB.getExecutionCount()) / 2;
      KnownArcs.insert(std::make_pair(Pred, &BB));
    }
    auto BI = BB.branch_info_begin();
    for (auto Succ : BB.successors()) {
      if (KnownArcs.count(std::make_pair(&BB, Succ))) {
        ++BI;
        continue;
      }
      BI->Count =
          std::min(BB.getExecutionCount(), Succ->getExecutionCount()) / 2;
      KnownArcs.insert(std::make_pair(&BB, Succ));
      break;
    }
  }
}

/// Associate each basic block with the BinaryLoop object corresponding to the
/// innermost loop containing this block.
DenseMap<const BinaryBasicBlock *, const BinaryLoop*>
createLoopNestLevelMap(BinaryFunction &BF) {
  DenseMap<const BinaryBasicBlock *, const BinaryLoop*> LoopNestLevel;
  auto &BLI = BF.getLoopInfo();

  for (auto &BB : BF) {
    LoopNestLevel[&BB] = BLI[&BB];
  }

  return LoopNestLevel;
}

/// Implement the idea in "SamplePGO - The Power of Profile Guided Optimizations
/// without the Usability Burden" by Diego Novillo to make basic block counts
/// equal if we show that A dominates B, B post-dominates A and they are in the
/// same loop and same loop nesting level.
void equalizeBBCounts(BinaryFunction &BF) {
  auto Info = DataflowInfoManager(BF.getBinaryContext(), BF, nullptr, nullptr);
  auto &DA = Info.getDominatorAnalysis();
  auto &PDA = Info.getPostDominatorAnalysis();
  auto &InsnToBB = Info.getInsnToBBMap();
  // These analyses work at the instruction granularity, but we really only need
  // basic block granularity here. So we'll use a set of visited edges to avoid
  // revisiting the same BBs again and again.
  DenseMap<const BinaryBasicBlock *, std::set<const BinaryBasicBlock *>>
      Visited;
  // Equivalence classes mapping. Each equivalence class is defined by the set
  // of BBs that obeys the aforementioned properties.
  DenseMap<const BinaryBasicBlock *, signed> BBsToEC;
  std::vector<std::vector<BinaryBasicBlock *>> Classes;

  BF.calculateLoopInfo();
  auto LoopNestLevel = createLoopNestLevelMap(BF);

  for (auto &BB : BF) {
    BBsToEC[&BB] = -1;
  }

  for (auto &BB : BF) {
    auto I = BB.begin();
    if (I == BB.end())
      continue;

    DA.doForAllDominators(*I, [&](const MCInst &DomInst) {
      auto *DomBB = InsnToBB[&DomInst];
      if (Visited[DomBB].count(&BB))
        return;
      Visited[DomBB].insert(&BB);
      if (!PDA.doesADominateB(*I, DomInst))
        return;
      if (LoopNestLevel[&BB] != LoopNestLevel[DomBB])
        return;
      if (BBsToEC[DomBB] == -1  && BBsToEC[&BB] == -1) {
        BBsToEC[DomBB] = Classes.size();
        BBsToEC[&BB] = Classes.size();
        Classes.emplace_back();
        Classes.back().push_back(DomBB);
        Classes.back().push_back(&BB);
        return;
      }
      if (BBsToEC[DomBB] == -1) {
        BBsToEC[DomBB] = BBsToEC[&BB];
        Classes[BBsToEC[&BB]].push_back(DomBB);
        return;
      }
      if (BBsToEC[&BB] == -1) {
        BBsToEC[&BB] = BBsToEC[DomBB];
        Classes[BBsToEC[DomBB]].push_back(&BB);
        return;
      }
      auto BBECNum = BBsToEC[&BB];
      auto DomEC = Classes[BBsToEC[DomBB]];
      auto BBEC = Classes[BBECNum];
      for (auto *Block : DomEC) {
        BBsToEC[Block] = BBECNum;
        BBEC.push_back(Block);
      }
      DomEC.clear();
    });
  }

  for (auto &Class : Classes) {
    uint64_t Max{0ULL};
    for (auto *BB : Class) {
      Max = std::max(Max, BB->getExecutionCount());
    }
    for (auto *BB : Class) {
      BB->setExecutionCount(Max);
    }
  }
}

} // end anonymous namespace

void estimateEdgeCounts(BinaryFunction &BF) {
  EdgeWeightMap PredEdgeWeights;
  EdgeWeightMap SuccEdgeWeights;
  if (!opts::IterativeGuess) {
    computeEdgeWeights<Inverse<BinaryBasicBlock *>>(BF, PredEdgeWeights);
    computeEdgeWeights<BinaryBasicBlock *>(BF, SuccEdgeWeights);
  }
  if (opts::EqualizeBBCounts) {
    DEBUG(BF.print(dbgs(), "before equalize BB counts", true));
    equalizeBBCounts(BF);
    DEBUG(BF.print(dbgs(), "after equalize BB counts", true));
  }
  if (opts::IterativeGuess)
    guessEdgeByIterativeApproach(BF);
  else
    guessEdgeByRelHotness(BF, /*UseSuccs=*/false, PredEdgeWeights,
                          SuccEdgeWeights);
  recalculateBBCounts(BF, /*AllEdges=*/false);
}

void solveMCF(BinaryFunction &BF, MCFCostFunction CostFunction) {
  Digraph Graph;
  using ArcMapTy = std::map<Digraph::ArcIt, int64_t>;
  using NodeMapTy = std::map<Digraph::Node, int64_t>;
  using SimplexTy = NetworkSimplex<Digraph, int64_t, int64_t>;
  using Node = Digraph::Node;
  using ArcIt = Digraph::ArcIt;
  ArcMapTy CostMap;
  ArcMapTy LowerCapacityMap;
  ArcMapTy UpperCapacityMap;
  NodeMapTy SupplyMap;
  NamedRegionTimer T("MCF", "MCF", BinaryFunctionPassManager::TimerGroupName,
                     BinaryFunctionPassManager::TimerGroupDesc, opts::TimeOpts);

  SimplexTy NS(Graph);

  Graph.reserveNode(BF.size() + 2);
  // Estimate the number of arcs
  Graph.reserveArc(BF.size() * 3);

  // Add source and sink
  Node Src = Graph.addNode();
  Node Sink = Graph.addNode();

  std::unordered_map<const BinaryBasicBlock *, Node> BBToNode;
  for (auto &BB : BF) {
    BBToNode[&BB] = Graph.addNode();
  }

  std::unordered_map<const BinaryBasicBlock *, std::vector<ArcIt>> BBToArcs;
  std::unordered_map<const BinaryBasicBlock *, std::vector<ArcIt>> BBToRArcs;
  for (auto BBI = BF.layout_begin(), E = BF.layout_end(); BBI != E; ++BBI) {
    auto &BB = **BBI;
    auto &ArcsVec = BBToArcs[&BB];
    auto &RArcsVec = BBToRArcs[&BB];
    ArcIt SrcToEntryArc;
    ArcIt ExitToSinkArc;

    if (BB.isEntryPoint()) {
      ArcIt A(Graph, Graph.addArc(Src, BBToNode[&BB]));
      LowerCapacityMap[A] = 0;
      UpperCapacityMap[A] = NS.INF;
      CostMap[A] = 0;
      SrcToEntryArc = A;
    }

    if (BB.succ_size() == 0) {
      ArcIt A(Graph, Graph.addArc(BBToNode[&BB], Sink));
      LowerCapacityMap[A] = 0;
      UpperCapacityMap[A] = NS.INF;
      CostMap[A] = 0;
      ExitToSinkArc = A;
    }

    auto BI = BB.branch_info_begin();
    int64_t TotalOutCount{0};

    auto AddSuccArc = [&](BinaryBasicBlock *Succ, uint64_t Count,
                          int IsFT) {
      ArcIt A(Graph, Graph.addArc(BBToNode[&BB], BBToNode[Succ]));
      switch (CostFunction) {
        case MCF_DISABLE:
          assert(0 && "Calling solveMCF with no cost function");
          break;
        case MCF_LINEAR:
          CostMap[A] =
              1000000000.0 / ((static_cast<double>(Count) / 1000.0) + IsFT + 2);
          break;
        case MCF_QUADRATIC:
          CostMap[A] =
              1000000000.0 /
              (pow(static_cast<double>(Count) / 100000.0, 2.0) + IsFT + 2);
          break;
        case MCF_LOG:
          CostMap[A] = 10000.0 /
            std::log(static_cast<double>(Count) / 1000.0 + IsFT + 2);
          break;
        case MCF_BLAMEFTS:
          CostMap[A] = 10000 / (IsFT * 9999 + 1);
          break;
      }
      assert (CostMap[A] >= 0 && "Overflow - cost must be non-negative");
      LowerCapacityMap[A] = 0;
      UpperCapacityMap[A] = NS.INF;
      ArcsVec.push_back(A);
      TotalOutCount += Count;

      // Add reverse arc
      if (opts::UseRArcs) {
        ArcIt RA(Graph, Graph.addArc(BBToNode[Succ], BBToNode[&BB]));
        // Make it 50 times harder to take a reverse edge
        CostMap[RA] = CostMap[A] * 50;
        assert (CostMap[RA] >= 0 && "Overflow - cost must be non-negative");
        LowerCapacityMap[RA] = 0;
        UpperCapacityMap[RA] = Count;
        RArcsVec.push_back(RA);
      }
    };

    size_t CurEdgeNum{0};
    auto Next = std::next(BBI);
    for (auto Succ : BB.successors()) {
      int IsFT = (Next != E && Succ == *Next) ? 1 : 0;
      AddSuccArc(Succ, BI->Count, IsFT);
      ++CurEdgeNum;
      ++BI;
    }

    for (auto LP : BB.landing_pads()) {
      AddSuccArc(LP, 0, 0);
    }

    int64_t TotalInCount{0};
    if (BB.pred_size() == 0 && BB.isEntryPoint()) {
      TotalInCount = BB.getExecutionCount();
    }
    for (auto Pred : BB.predecessors()) {
      TotalInCount += Pred->getBranchInfo(BB).Count;
    }

    int64_t Surplus = TotalInCount - TotalOutCount;
    // Already obeys flow conservation at this node
    if (Surplus == 0)
      continue;

    if (Surplus > 0) {
      if (!BB.isEntryPoint()) {
        ArcIt A(Graph, Graph.addArc(Src, BBToNode[&BB]));
        CostMap[A] = 0;
        LowerCapacityMap[A] = Surplus;
        UpperCapacityMap[A] = Surplus;
        SupplyMap[Src] += Surplus;
        SupplyMap[Sink] -= Surplus;
        continue;
      }
      // Reuse our existing arc if this is the entry
      LowerCapacityMap[SrcToEntryArc] = Surplus;
      SupplyMap[Src] += Surplus;
      SupplyMap[Sink] -= Surplus;
      continue;
    }

    // Deficit
    SupplyMap[Src] -= Surplus;
    SupplyMap[Sink] += Surplus;
    if (BB.succ_size() > 0) {
      ArcIt SA(Graph, Graph.addArc(BBToNode[&BB], Sink));
      CostMap[SA] = 0;
      LowerCapacityMap[SA] = -Surplus;
      UpperCapacityMap[SA] = -Surplus;
    } else {
      // This is an exit block, we already have an arc to the sink
      LowerCapacityMap[ExitToSinkArc] = -Surplus;
    }
  }

  NS.reset();
  NS.costMap(CostMap)
    .upperMap(UpperCapacityMap)
    .lowerMap(LowerCapacityMap)
    .supplyMap(SupplyMap);

  SimplexTy::ProblemType Result = NS.run();

  DEBUG(BF.print(dbgs(), "before MCF", true));

  if (Result == SimplexTy::INFEASIBLE) {
    dbgs() << "BOLT WARNING: Infeasible max-flow problem created for "
           << BF << " - Disabling flow fixups for this function.\n";
    return;
  } else if (Result == SimplexTy::UNBOUNDED) {
    dbgs() << "BOLT-INTERNAL ERROR: Unbounded max-flow problem created for "
           << BF << "\n";
    return;
  }

  // Fix our edge counts
  for (auto BBI = BF.layout_begin(), E = BF.layout_end(); BBI != E; ++BBI) {
    auto &BB = **BBI;
    auto &ArcsVec = BBToArcs[&BB];
    auto &RArcsVec = BBToRArcs[&BB];

    assert(ArcsVec.size() == BB.succ_size() + BB.lp_size() &&
           "Incorrect mapping to arcs");
    uint64_t TotalOut{0};
    auto ArcIter = ArcsVec.begin();
    auto RArcIter = RArcsVec.begin();
    auto BI = BB.branch_info_begin();
    for (auto Succ : BB.successors()) {
      auto Flow = NS.flow(*ArcIter);
      assert (Flow >= 0 && "Negative flow");
      BI->Count += Flow;
      TotalOut += BI->Count;
      if (opts::UseRArcs) {
        auto RFlow = NS.flow(*RArcIter);
        assert (RFlow >= 0 && "Negative flow");
        BI->Count -= RFlow;
        TotalOut -= RFlow;
        Flow -= RFlow;
        ++RArcIter;
      }
      ++BI;
      ++ArcIter;
      Succ->setExecutionCount(Succ->getExecutionCount() + Flow);
    }

    if (BB.pred_size() == 0)
      BB.setExecutionCount(TotalOut);
  }

  uint64_t NewFuncCount{0};
  for (auto &BB : BF) {
    if (BB.isEntryPoint())
      NewFuncCount += BB.getExecutionCount();
  }
  BF.setExecutionCount(NewFuncCount);

  DEBUG(BF.print(dbgs(), "after MCF", true));
}

}
}
